Restoring modules from user's default
[2019-12-08 15:29:12,632 INFO] Extracting features...
[2019-12-08 15:29:12,672 INFO]  * number of source features: 0.
[2019-12-08 15:29:12,672 INFO]  * number of target features: 0.
[2019-12-08 15:29:12,672 INFO] Building `Fields` object...
[2019-12-08 15:29:12,672 INFO] Building & saving training data...
[2019-12-08 15:29:12,867 INFO] Building shard 0.
[2019-12-08 15:29:16,760 INFO]  * saving 0th train data shard to Data/SVO_AN/prepro.train.0.pt.
[2019-12-08 15:29:19,723 INFO]  * tgt vocab size: 42.
[2019-12-08 15:29:19,723 INFO]  * src vocab size: 38.
[2019-12-08 15:29:19,730 INFO] Building & saving validation data...
[2019-12-08 15:29:19,781 INFO] Building shard 0.
[2019-12-08 15:29:20,052 INFO]  * saving 0th valid data shard to Data/SVO_AN/prepro.valid.0.pt.
[2019-12-08 15:29:21,434 INFO]  * src vocab size = 38
[2019-12-08 15:29:21,434 INFO]  * tgt vocab size = 42
[2019-12-08 15:29:21,434 INFO] Building model...
[2019-12-08 15:29:21,552 INFO] NMTModel(
  (encoder): RNNEncoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(38, 500, padding_idx=1)
        )
      )
    )
    (rnn): LSTM(500, 500, num_layers=2, dropout=0.3)
  )
  (decoder): InputFeedRNNDecoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(42, 500, padding_idx=1)
        )
      )
    )
    (dropout): Dropout(p=0.3, inplace=False)
    (rnn): StackedLSTM(
      (dropout): Dropout(p=0.3, inplace=False)
      (layers): ModuleList(
        (0): LSTMCell(1000, 500)
        (1): LSTMCell(500, 500)
      )
    )
    (attn): GlobalAttention(
      (linear_in): Linear(in_features=500, out_features=500, bias=False)
      (linear_out): Linear(in_features=1000, out_features=500, bias=False)
    )
  )
  (generator): Sequential(
    (0): Linear(in_features=500, out_features=42, bias=True)
    (1): Cast()
    (2): LogSoftmax()
  )
)
[2019-12-08 15:29:21,553 INFO] encoder: 4027000
[2019-12-08 15:29:21,553 INFO] decoder: 5800042
[2019-12-08 15:29:21,553 INFO] * number of parameters: 9827042
[2019-12-08 15:29:21,559 INFO] Starting training on CPU, could be very slow
[2019-12-08 15:29:21,559 INFO] Start training loop and validate every 10000 steps...
[2019-12-08 15:29:21,560 INFO] Loading dataset from Data/SVO_AN/prepro.train.0.pt
[2019-12-08 15:29:22,606 INFO] number of examples: 128841
[2019-12-08 15:32:07,193 INFO] Step 50/ 2013; acc:  12.58; ppl: 363.50; xent: 5.90; lr: 1.00000; 155/174 tok/s;    166 sec
[2019-12-08 15:34:50,598 INFO] Step 100/ 2013; acc:  18.25; ppl: 65.71; xent: 4.19; lr: 1.00000; 157/176 tok/s;    329 sec
[2019-12-08 15:37:32,333 INFO] Step 150/ 2013; acc:  32.31; ppl: 11.75; xent: 2.46; lr: 1.00000; 158/178 tok/s;    491 sec
[2019-12-08 15:40:08,248 INFO] Step 200/ 2013; acc:  43.96; ppl:  4.53; xent: 1.51; lr: 1.00000; 164/185 tok/s;    647 sec
slurmstepd: error: *** JOB 8938724 ON pg-node189 CANCELLED AT 2019-12-08T15:42:22 ***


###############################################################################
Peregrine Cluster
Job 8938724 for user 's2964007'
Finished at: Sun Dec  8 15:42:23 CET 2019

Job details:
============

Name                : onmt_test
User                : s2964007
Partition           : short
Nodes               : pg-node189
Cores               : 1
State               : CANCELLED,CANCELLED by 32964007
Submit              : 2019-12-08T15:29:05
Start               : 2019-12-08T15:29:06
End                 : 2019-12-08T15:42:23
Reserved walltime   : 00:20:00
Used walltime       : 00:13:17
Used CPU time       : 00:12:57 (efficiency: 97.50%)
% User (Computation): 55.04%
% System (I/O)      : 44.96%
Mem reserved        : 2000M/node
Max Mem used        : 691.89M (pg-node189)
Max Disk Write      : 50.59M (pg-node189)
Max Disk Read       : 74.75M (pg-node189)


Acknowledgements:
=================

Please see this page if you want to acknowledge Peregrine in your publications:

https://redmine.hpc.rug.nl/redmine/projects/peregrine/wiki/ScientificOutput

################################################################################
